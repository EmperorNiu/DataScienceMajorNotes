## 2020-2021 信息检索复习提纲

#### 综述

80基础+20拓展

1. 布尔模型，向量模型，概率模型，语言模型
2. 相关反馈和查询扩展
3. 文本处理 的步骤
4. 文本分类的技术
5. 检索系统的评价指标，每种方法的特点，优缺点

题型：计算，填空，选择题

#### L0 布尔检索

1. **什么是信息检索**，应用场景，给定用户需求
2. **传统与现在的差异**

2. 如何提高效率

3. **倒排索引的构建**，结构组织。
   1.  为什么包含这一项
   2. posting list 为什么按序
   3. 构建过程
   4. and 从小开始合并
   5. O（m+n）
   6. 转化成合取范式
4. 布尔表达式的优缺点
5. 正确率和召回率

#### L1

1. 词条和词项
2. 词条化需要注意的问题
3. 搜索引擎中的分词方法
   1. 基于词典
   2. 基于统计的
   3. 基于启发式规则的
4. 停用词
5. 词条的归一化
6. 拼写错误问题：soundex 、词干还原（了解概念）
7. Potter不考
8. **跳表法** 
   1. 步长长短对检索的影响
9. **支持短语查询的方法**
   1. 双词索引
      1. 扩展的双词索引 标注词性，更好表达语义
   2. 带位置信息的索引
      1. 邻近式查询
10. 类似题：你认为中文处理和英文处理有什么区别

#### L3

1. 通配符查询是怎么支持的
   1. 树的结构
   2. 轮排索引的构建

2. 哈希表和树结构的优缺点
3. 不考k-gram
4. 基于编辑距离的拼写校正的两种方法
   1. 编辑距离
   2. 加上字符交换的编辑距离

#### L4

外部排序应该不考，老师含糊其辞

1. BSBI算法的过程
2. SPIMI的关键思想

#### L5

1. **简答：索引压缩有哪些方法，不会现场让你压缩**
2. zipf定律是什么定律，能举例
3. dictionary as string的过程
4. 前端压缩
5. postinglist的压缩：差值表示，变长编码 **估计不考**
6. 其他不考

#### L6

1. 为什么进行排序
2. 评分方法
   1. Jaccard系数	(会算)，**不足**
3. 什么是词袋模型，缺点
4. tf-idf 
   1. tf公式会给
   2. 为什么要有idf
   3. tf，df，cf的关系
5. 向量空间模型怎么进行查询
   1. cos相似度
   2. **文档长度归一化，为什么**

#### L7 计算题

1. 列举检验排序好坏的方法
2. TopK的加速方法
   1. 加速cos计算
   2. 用堆方法，**不会考堆**
   3. 提前终止
3. 静态质量g(d)
4. 胜者表

#### L8 检索评价&结果摘要

1. IR中评价什么

   1. 效率
      1. 时间开销
      2. 空间开销
      3. 响应速度
   2. 效果
      1. 返回的文档中有多少相关文档
      2. 所有相关文档中返回了多少
      3. 返回的靠不靠前
   3. 其他指标、
      1. 覆盖率
      2. 访问量
      3. 数据更新速度

2. 召回率难以计算 --> Pooling方法

   1. 很难找到所有正确文档
   2. Pooling方法： 对多个检索系统的Top N个结果组成的集合进行人工标注，标注出的相关文档集合作为整个相关文档集合

3. 为什么使用F值，为什么不使用Accuracy

   1. 为什么使用F值
      - 如果采用算术平均计算F值，那么一个返回全部文档的搜索引擎的F值就不低于50%，这有些过高
      - 不管是P还是R，如果十分低，那么结果应该表现出来，即这样的情形下最终的F值应该有所惩罚
      - 最小值方法不平滑而且不易加权
   2. 为什么不使用Accuracy
      1. 不相关文档太多，什么都不返回可能对大部分查询来说可以得到99.99%以上的精确率
      2. 信息检索用户希望找到某些文档并且能够容忍结果中有一定的不相关性。返回一些即使不好的文档也比不返回任何文档强

4. 正确率召回率曲线

   - 求出在召回率分别为0%,10%,20%,30%,…,90%,100%上对应的正确率，然后描出图像。在上面的曲线对应的系统结果更好

   - 不存在10%, 20%,…,90%的召回率点，而只存在33.3%, 66.7%, 100%三个召回率点。在这种情况下，需要利用存在的召回率点对不存在的召回率点进行插值。对于t%，如果不存在该召回率点，则定义t%的正确率为从t%到100%(>=t%)中最大的正确率值
   - 优点
     - 简单直观
     - 既考虑了检索结果的覆盖度，又考虑了检索结果的排序情况
   - 缺点
     - 单个查询的P-R曲线虽然直观，但是难以明确表示两个查询的检索结果的优劣、
   - 基于P-R曲线的单一指标
     - Break Point：P-R曲线上P=R的那个点
     - 11点平均正确率(11 point average precision)：在召回率分别为0,0.1,0.2,…,1.0的十一个点上的正确率求平均，等价于插值的AP

5. 宏平均(Macro Average)和微平均

   - 宏平均: 对每个查询求出某个指标，然后对这些指标进行算术平均
   - 微平均：Average): 将所有查询视为一个查询，将各种情况的文档总数求和，然后进行指标的计算
   - MAP(Mean AP)：对所有查询的AP求宏平均

6. **覆盖率**: 表示系统找到的用户已知的相关文档比例

   设用户已知的相关文档集合为$U$，检索结果和$U$的集合为$Ru$
   $$
   Coverage=\frac{|Ru|}{|U|}
   $$
   出新率(Novelty Ratio)，假定检索结果中返回一些用户以前未知的相关文档Rk
   $$
   N=\frac{|Rk|}{|Ru|+|Rk|}
   $$
   RR：第一个标准答案的位置的倒数

   MRR：对问题集合的RR求平均

7. Bpref、GMAP、NDGG等一系列指标，**不需要背公式但要会算**（估计考Bpref或NDGG）

   1. Bpref
      
      - 相关性判断完全的情况下，利用Bpref和MAP进行评价的结果很一致，但是相关性判断不完全的情况下，Bpref更鲁棒
      
      - $$
        bpref = \frac{1}{R}\sum_r(1-\frac{|n_r|}{R})
        $$
      
        - r是相关文档
        - n是r前不相关文档集合大小

#### L9

相关反馈的概念，基本思想，**哪几种方法，并简答是什么意思**

Rachel算法 $\gamma$为什么取0

搜索引擎是否使用相关反馈，为什么

查询扩展的概念

#### L10

不考

#### L11

1. 概率检索模型

2. 概率排序的原理
3. logistics应该不考
4. BIM 
   1. 生成式的模型，为什么，
   2. 两个假设
   3. 计算
   4. 多元贝努力和多项式分布的区分和计算
   5. 优缺点
5. BM25公式含义

### L12 语言模型

语言模型(LM)：基于单词序列的概率分布

1. n元模型表达式：
   $$
   P(w_1w_2\dots w_n)=P(w_1)\prod_{i=2}^nP(w_i|w_{i-1}\dots w_1)
   $$
   设词典大小为M

   n元模型参数：$M+M^2+\cdots+M^N=\frac{M^{N+1}-M}{M-1}$

2. 1元模型存在什么问题

   - 没用使用上下文信息
   - 没有语序
   - ？

3. 语言片段出现的概率计算

4. **查询似然模型** QLM

   - 定义：把相关度看成是每篇文档对应的语言下生成该查询的可能性 $P(Q|D)$

   - QLM计算公式
     $$
     RSV(Q,D)=P(Q|D)=P(Q|M_D)=\prod_{w\in Q}P(w|M_D)^{c(w,Q)}
     $$

   - 不能把$P(w|M_D)$理解为w在文档D中的概

5. **文档似然模型**：查询建模，计算文档的似然

6. QLM三步

   1. 第一步：根据文档D（样本），估计文档模型$M_D$(总体)，在一元模型下，计算所有词项w的概率$P(w|M_D)$
      - 基于多元贝努力模型
      - 基于多项式模型   $\surd$
   2. 第二步：计算在模型$M_D$下生成查询Q的似然
   3. 第三步：按照得分对所有文档排序

7. 查询似然、文档似然、模型比较的关系

   <img src="SLMIR.jpg">

   - 查询似然类：文档建模，计算查询的似然
   - 文档似然类：查询建模，计算文档的似然
   - 模型比较类：文档建模、查询建模，计算两个模型的距离，KL距离模型

8. 翻译模型不考

9. SLMIR 和 VSM的比较

   - 相同点
     -  模型中都直接使用了词项频率，但是在SLMIR中没有进行放缩变化(scaled)
     - 本质上概率表示已经进行了长度归一化
     - 文档频率和文档集频率混合以后和idf的效果相当
   - 不同点
     - SLMIR：基于概率论
     -  VSM： 基于相似度，一个线性代数中的概念
     - 文档集频率 vs. 文档概率
     - 词项频率、归一化等计算细节

#### L13

1. 朴素贝叶斯分类器
   1. 平滑
   2. 计算
   3. 公式不给
2. Rocchio能处理什么问题不能处理什么问题
3. KNN了解

#### L14

- 如何特征选择

- Rocchio分类器
- K近邻分类器

#### L15

1. 看图聚类

2. 聚类评价

